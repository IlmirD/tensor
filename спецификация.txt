Веб разработчики тексты обычно помещают в теге p, поэтому для универсальности ищем тексты в
этом теге, однако, все равно появляется мусор, например, в некоторых сайтах копирайт или footer
также помещены в этот тег и как следствие набирается лишняя информация. Чтобы этого не допустить 
в файле parsing_parameter можно задать название класса, содержащий нужный текст.

Некоторые ресурсы блокируют парсинг: комсомольская правда(kp.ru) ...

Алгоритм:

1. Сначала формируем путь к файлу и название по url. Url берем из консоли

2. Парсим страницу с помощью Beautiful Soup и сохраняем результат

Для выполнения скрипта нужно ввести в консоли команду:
python article_parser.py [ссылка на статью]
нужно исключить знак вопроса и амперсанды

Тестированные ссылки:
    https://www.rbc.ru/life/news/633f07319a79470394be27ba
    https://lenta.ru/news/2022/10/06/sprosdown/

